[["index.html", "Notes for Math, Probability, and Statistics Chapter 1 Contents", " Notes for Math, Probability, and Statistics Jessica B 2023-05-26 Chapter 1 Contents "],["axioms-of-kolmogorov.html", "Chapter 2 Axioms of Kolmogorov 2.1 Sets, Sample Spaces, and events 2.2 Axioms of Kolmogorov 2.3 Implied consequences of the Axioms 2.4 CONTINUITY OF PROBABILITY FUNCTIONS", " Chapter 2 Axioms of Kolmogorov There are three rules defined for creating a probabilistic model: The probability of an event must be greater than zero That the probabilities for all disjoint events in a sample space must sum to one The total probability for the union of events is equal to the sum of their individual probabilities. This is an ultra simplified statement of the axioms that govern modern probability theory. In 1933, these rules were formally axiomized by the great Andrey Nikolaevich Kolmogorov. Before describing the axioms more formally, lets review some set theory. 2.1 Sets, Sample Spaces, and events Sets are collections of distinct elements. A sample space is the set of disjoint, collectively exhaustive outcomes taken at a determined level of granularity. A sample space can be described as finite or infinite, discrete or continuous. 2.1.1 Definitions and LaTex code. Symbol Name LaTeX \\(\\sim\\) Similar \\sim \\(=\\) Equality, sets are identical i.e. contain the same elements = \\(\\cup\\) Intersection \\cup \\(\\cap\\) Union \\cap \\(\\in\\) Belongs to \\in \\(\\varnothing\\) Null set \\varnothing \\(\\Omega\\), \\(S\\) Universal set \\Omega \\(\\omega\\), \\(s\\) Atom, singleton \\omega \\(\\subset\\) Proper subset, S is contained within A, sometimes used S = A \\subset \\(\\subseteq\\) Subset, if S is contained within A \\subseteq \\(\\bigcup\\) infinitary union, generalized union, unified union \\bigcup \\(\\bigcap\\) infinitary intersection, generalized intersection, unified intersection cap \\bigcap 2.1.2 More Set Definitions complement, sum, difference, certainty, impossibility, mutual exclusivity.. 2.1.3 Relational Laws Communicative Associative Distributive DeMorgan’s 1st and 2nd laws [add proofs, also identities are usually proven elementwise] 2.2 Axioms of Kolmogorov Non-negativity Axiom \\[ \\text{For any event A in our sample space, } \\mathbb{P}(A)≥0 \\] Unity Axiom \\[ \\text{Normalization, also called the assumption of unit measure,}\\\\ \\text{defines the probability of the sample space } \\Omega \\text{ as } \\mathbb{P}(\\Omega)=1 \\] \\(\\sigma\\)-additivity Axiom Any countable pairwise disjoint sequence (i.e. A1,A2,...), even countably infinite sequences of events satisfies \\(P(\\bigcup_{i=1}^{\\infty}A_{i}) = \\sum_{n=1}^{\\infty}P(A_{i})\\) where pairwise disjoint: i.e. \\(A_iA_j = \\varnothing\\), where \\(i \\neq j\\) (countable sequence of events: \\(A_1,A_2,...\\)) Finite additivity is 2.3 Implied consequences of the Axioms Demonstrating these immediate consequences illustrates the power of the third axiom, and its interaction with the remaining two axioms. (Theorem 1.1) Probability of the empty set \\(P(\\varnothing) = 0\\) (Theorem 1.2) Finite Additivity (Theorem 1.3) “Average” (Theorem 1.4) The complement rule (Theorem 1.5) Monotonicity Corollary: The numeric bound (Theorem 1.6) Inclusion-Exclusion Principal (Theorem 1.7) P(A) = P(AB) + P(AB^C) (Theorem 1.8) Continuity of Probability Function Booles ineqauilty 2.3.1 A word of Probability Measures 2.4 CONTINUITY OF PROBABILITY FUNCTIONS "],["combinatorics.html", "Chapter 3 Combinatorics 3.1 Counting Principal 3.2 Number of Sets in a Subset 3.3 Permutations 3.4 Combinations", " Chapter 3 Combinatorics 3.1 Counting Principal Fundamental Counting Principle a.k.a. generalized counting principal, Also known as the rule of product, or the multiplication principal. Let \\(E_1, E_2, ..., E_k\\) be sets with \\(n_1,n_2, ...,n_k\\) elements,respectively. Then there are \\(n_1×n_2×n_3×···×n_k\\) ways in which we can, first, choose an element of \\(E_1\\), then an element of \\(E_2\\), then an element of \\(E_3\\)… and finally an element of \\(E_k\\). Combinatorial principles - Wikipedia 3.2 Number of Sets in a Subset The set of all subsets of A is called the power set of A. We can calculate the number of subsets in a set as \\(2^n\\), because each element can be either included or excluded (hence the two options) Mathematically we can say that 3.3 Permutations A permutation is the number of ways we can order \\(n\\) distinct objects, from the general counting principal it follows that we have \\(n\\) ways to make the first selection, the we will have one less ways to make our next selection, and so on. For example if we have ten objects, there is ten ways to… \\[ (n)(n−1)(n−2)···(1)=n! \\] This is because of there are of the ways to \\(n\\) ways to choose the first object, n-1 ways to choose the second, all the way to only \\(1\\) possible way to choose the last object. We use the notation \\(_nP_r\\) to denote the number of permutations of a set \\(A\\) containing \\(n\\) elements taken \\(r\\) at a time where \\((1 ≤ r ≤ n)\\) The number of r-element permutations of a set containing n objects is given by \\[ _nP_r = \\frac{n!}{(n-r)!} \\] (note: to avoid division by zero when \\(n=r\\) we define \\(0! = 1\\)) To derive the formula for \\(_nP_r\\) we consider the number of choices for each selection. Since \\(A\\) has \\(n\\) elements, the number of choices for the first object in the \\(r\\)-element permutation is \\(n\\). For the next selection there will be \\(n-1\\) options, followed by \\(n-2\\) options for the selection that follows after that, we do this until our last selection, which is the \\(r\\)th object. This object has possible \\(n − (r − 1)\\) choices. This leads us to the equation \\[ _nP_r =n(n−1)(n−2)···(n−r+1) \\] We can also note how this relates to a simple permutation which we discussed above \\[ _nP_n =n(n−1)(n−2)···(n−n+1)=n! \\] How we get our general formula \\(_nP_r\\) is by manipulating the equation \\(n(n−1)(n−2)···(n−r+1)\\) which is done by multiplying both sides by \\((n-r)!\\), then dividing both sides by \\((n-r)!\\) Which leads us to the formula \\[ _nP_r = \\frac{n!}{(n-r)!} \\] [reorganize to follow and add actual derivation] However the formula above is valid only if all of the objects of the set are distinguishable from each other. If there are repeated elements (e.g. the letter E in the word “BERKELEY”) we must take add [karapanian veusus brungard] \\[ \\frac{n!}{n_1! × n_2 ! × · · · × n_k!} \\] An example of repeated elements in a permutation problem would be: How many different 10-letter codes can be made using three a’s, four b’s, and three c’s? Which would have the solution \\(\\frac{10!}{(3!*4!*3!)}\\), since you need to use to above theorem to divide out the elements that would otherwise be over-counted. 3.4 Combinations [motivation add how its different than combination] we have for \\(r \\le n\\) \\[ \\binom{n}{r}=\\frac{n!}{r!(n-r)!} \\] We are calculating the number of \\(r\\)-element subsets from a \\(n\\)-element set, where order matters. This is the number of all r-element combinations of n objects, where we only use valid non-negative integers (e.g. 0,1,2, …) where \\(r \\le n\\). [add derivation!!!!! xr! = npr] consider \\[ \\binom{n}{n}=\\binom{n}{0}=1 \\] \\[ \\binom{n}{n}=\\frac{n!}{n!(n-n)!=1} \\] consider \\[ \\binom{n}{1}=\\binom{n}{n-1} \\] consider where \\(0 \\le r \\le n\\) \\[ \\binom{n}{r}=\\binom{n}{n-r} \\] and \\[ \\binom{n+1}{r}=\\binom{n}{r}+\\binom{n}{r-1} \\] [write more thoughts about this and how to verify algebraically or using combinatorics] [add unordered sampling with replacement] [example 2.22 and binomial expansion] "],["conditional-probability.html", "Chapter 4 Conditional Probability 4.1 Conditional Probability is a Probability Measure 4.2 Reduction of a Sample Space 4.3 Law of Multiplication 4.4 Law of Total Probability 4.5 Bayes’ Formula", " Chapter 4 Conditional Probability Conditional probability is not a theorem, nor a conjecture. It is not a lemma or a corollary. Instead conditional probability is a fundamental concept which is inherently understood…. It is obvious that the conditional probability \\(\\mathbb{P}(A|B)\\) gives an advantage when knowing the occurrence of B changes the occurrence of A. The probability of \\(\\mathbb{P}(A|B)\\) is obviously given by the ratio of the relative frequency of the intersection of A and B and the relative frequency of B. We can also state this as “the ratio of the probability of joint occurrence of A and B and the probability of B.” Conditional probability can be can be visualized when we think in terms of area…. We define conditional probability as \\[ \\mathbb{P}(A|B)=\\frac{\\mathbb{P}(AB)}{\\mathbb{P}(B)} \\] where \\(\\mathbb{P}(B)&gt;0\\). [Supporting example coming] Intersection versus joint occurance of events… I thought it was the same thing. But I found myself getting bogged down in set theory. We know of course that P(AB) is the intersection of common elements between sets A and B. The joint occurance better describles the probability that events are to occur. 4.1 Conditional Probability is a Probability Measure That is, they satisfy the same axioms that ordinary probabilities satisfy. This enables us to use the theorems that are true for probabilities for conditional probabilities as well. [Proof coming soon] 4.2 Reduction of a Sample Space It is possible to reduce a sample space e.g. from (S to B) and have a smaller set of subsets. Making it easier to calculate conditioned probabilities. 4.3 Law of Multiplication Understand that conditional probability represents the relation between \\(\\mathbb{P}(A|B)\\) and \\(\\frac{\\mathbb{P}(AB)}{\\mathbb{P}(B)}\\) where \\(\\mathbb{P}(B) &gt; 0\\). By simply multiplying both sides by the \\(\\mathbb{P}(B)\\), The law of multiplication demonstrates that probability of the joint occurrence of A and B is the product of the probability of B and the conditional probability of A given that B has occurred. \\[ \\mathbb{P}(AB)=\\mathbb{P}(A|B)\\mathbb{P}(B), \\text{ where } \\mathbb{P}(B)&gt;0 \\] also, \\[ \\mathbb{P}(AB)=\\mathbb{P}(BA)=\\mathbb{P}(B|A)\\mathbb{P}(A), \\text{ where } \\mathbb{P}(A) &gt; 0 \\] We can also calculate the joint probability of three events by using association laws, e.g. \\(P(ABC)=P(A(BC))=\\mathbb{P}(A)P(B|A)P()\\) Generalizing these theorems stated can be extended to \\(n\\) events to \\(k\\) events, the resulting formula can be proved by mathematical induction. The theorem is as follows if \\(P(A_1 A_2 A_3 ...A_{n−1}) &gt; 0\\), then \\[ P(A_1 A_2 A_3 ...A_{n−1}A_n) = P(A_1)P(A_2 | A_1)P(A_3 | A_1A_2)···P(A_n | A_1A_2A_3 ···A_{n−1}) \\] 4.4 Law of Total Probability \\[ \\mathbb{P}(A) = \\mathbb{P}(A|B)\\mathbb{P}(A) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c) \\] Proof: Theorem 1.7 To generalize the theorem we define the partion of \\(S\\) 4.5 Bayes’ Formula Bayes’ Rule is a simple calculation but a big idea about beliefs. Consider that the partitioned sample space we imagine for the law of total probability. With Bayes’ Rule we are update our belief about something given that we know some other event is true or has occurred. We want to calculated the probability of an unknown event occur Think of it has Hypothesis given evidence….. More literally it is hypothesis given evidence is true \\[ P(H|E) \\] Prior: In order to update our beliefs… we need to consider our prior knowledge \\(P(H)\\) Liklihood: Our subset where we consider the liklihood that our hypothesis is true under the conditional evidence \\(P(E|H)\\) Post "],["random-variables.html", "Chapter 5 Random Variables 5.1 Transformations of Random Variables 5.2 Distribution Functions 5.3 Probability Mass Functions 5.4 Probability Density Function 5.5 Expected Value 5.6 Properties of Expected Value 5.7 Variance 5.8 Moments 5.9 Standardized Random Variables 5.10 Law of the Unconscious Statistician (LOTUS)", " Chapter 5 Random Variables The concept of random variables allows us to explore what is unknown, or governed by randomness. We define a random variable as a real-valued function that maps a given event/outcome from a random experiment to a real number. The most formal, axiomatic definition of a random variable involves measure theory. \\[ X:\\Omega\\rightarrow \\mathbb{R} \\] Support Set - The support set is the set of possible values of \\(X\\). - Also refers to the domain of a random variable. - Is discrete or continuous depending on the data involved. A random variable is not it’s probability distribution. - A random variable is a representation of the possible outcomes of a random process, while the probability distribution provides a way to describe the likelihood or probability of each possible outcome. - e.g. A binomial random variable is not a binomial distribution - X is a function, not to be confused with a distribution function, or not f(x) is not p(x)! Random Variable Examples The outcome of a coin toss can be represented by a random variable that takes the value 1 if the coin lands heads and 0 if it lands tails. 5.1 Transformations of Random Variables A transformed variable will have a new distribution with different characteristics compared to the original distribution. 5.1.1 Transformations on a single random variable Linear transformation: A linear transformation of a random variable X can be defined as Y = aX + b, where a and b are constants. This transformation can be useful in situations where we want to scale or shift the variable. Exponential transformation: An exponential transformation of a random variable X can be defined as Y = e^X. This transformation can be useful in situations where the data is skewed or has a long tail. Logarithmic transformation: A logarithmic transformation of a random variable X can be defined as Y = log(X). This transformation can be useful in situations where the data is heavily skewed or the variable is expressed in units of magnitude. Box-Cox transformation: The Box-Cox transformation is a family of power transformations that can be used to stabilize the variance of a random variable. The transformation is defined as Y = [(X^λ)-1]/λ, where λ is a parameter that can be estimated from the data. Square root transformation: A square root transformation of a random variable X can be defined as Y = sqrt(X). This transformation can be useful in situations where the data is non-negative and the variance is proportional to the mean. Inverse transformation: An inverse transformation of a random variable X can be defined as Y = 1/X. This transformation can be useful in situations where the data is expressed in ratios or rates. 5.1.2 Transformations on multiple random variables (from the same sample space) Linear transformation: A linear transformation of X, Y, and Z can be defined as W = aX + bY + cZ, where a, b, and c are constants. This transformation can be useful in situations where we want to combine the information from three variables into a single variable. Multiplication: Multiplying three random variables X, Y, and Z can result in a new random variable W = XYZ. This can be useful in situations where we are interested in the product of three variables. Division: Dividing two random variables X and Y can result in a new random variable W = X/Y/Z. This can be useful in situations where we want to normalize one variable by two others. Addition: Adding three random variables X, Y, and Z can result in a new random variable W = X + Y + Z. This can be useful in situations where we are interested in the sum of three variables. Subtraction: Subtracting three random variables X, Y, and Z can result in a new random variable W = X - Y - Z. This can be useful in situations where we are interested in the difference between three variables. Function transformation: Applying a function to X, Y, and Z can result in a new random variable W = f(X,Y,Z). This can be useful in situations where we want to transform the variables in a non-linear way. In general, we can think of transforming n random variables using the above methods by defining a new random variable W as a function of the n variables, such as W = f(X1,X2,...,Xn). The choice of transformation will depend on the specific problem and the goals of the analysis. 5.1.3 Additional Notes We can have several random variables defined on a sample space. Consider trying to randomly plot points on a plane in a circle, or within a boundary. this is a transformation on two random variables (X and Y are (x,y)) 5.2 Distribution Functions Definition: A distribution function of a random variable \\(X\\) is a function \\(F\\) from \\((-\\infty, +\\infty)\\) to \\(\\mathbb{R}\\) defined by\\(F(t)=P(X \\le t)\\). The CDF characterizes a random variable. Properties From the definition of a distribution function, the following properties are determined: F(t) is non-decreasing F(t) is right continuous satisfies \\(\\lim_{t \\rightarrow \\infty}= 1\\) satisfies \\(\\lim_{t \\rightarrow -\\infty}= 0\\) If the above properties are satisfied then we have a CDF. Recall that the CDF can characterize a random variable, how is this done? Considered the events that are represented as the following inequalities, if \\(P(X \\le t)\\) is known for all \\(t \\in \\mathbb{R}\\) all of the following events can be calculated. \\[ (X \\le a) \\qquad (X &lt; a) \\qquad (X \\ge a) \\qquad (X &gt; a) \\qquad (X = a) \\] \\[ (a \\le X \\le b) \\qquad (a &lt; X &lt; b) \\qquad (a &lt; X \\le b) \\qquad (a \\le X &lt; b) \\] [needs proof from section 4.2] In general, the respective discrete and continuous CDFs are as follows, but take a closer look at the formulas, they are using p(x) and f(x), respectively to calculate F(t). If the PDF and PMF are derived from the CDF, how are we using them to calculate the CDF? \\[ F_X(t) = P(X \\le t) = \\sum_{\\{x \\in R_x | x\\le t\\}} p_X(x)\\tag{Discrete} \\] \\[ F(t) = P(X \\le t) = \\int_{-\\infty}^{t} f_X(x) dx \\tag{Continuous} \\] \\[ F(t) \\] 5.2.1 Additional Notes For discrete random variables, cdfs are step functions. P(X = a) = 0 PDF and PMF are derived from the CDF The probability integral transform theorem is also known as the Borel-Kolmogorov paradox or the Borel-Kolmogorov theorem: t can be shown that there exists a sample space S with a probability function and a random variable X over S such that the distribution function of X is F. 5.3 Probability Mass Functions Also called a PMF, probability function, or discrete probability function. Defined as a real-valued function from support set of a random variable \\(X\\) to \\(\\mathbb{R}\\), i.e. \\(p: \\mathbb{R_x} \\rightarrow \\mathbb{R}\\). \\[ p_X(x) = P(X=x) = P(\\{\\omega \\in \\Omega | X(\\omega)=x\\}) \\] a proper PMF satisfies the following properties \\[ p(x) \\ge 0 \\] and \\[ \\sum_{x \\in R_x}p(x)=1 \\] 5.4 Probability Density Function Defined as a real-valued function from \\(\\mathbb{R}\\) to \\(\\mathbb{R}\\), i.e. \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\) a proper PMF satisfies the following properties \\[ \\tag{1} f(x) \\ge 0, \\quad \\forall x \\in \\mathbb{R} \\] and \\[ \\int_{-\\infty}^{\\infty}f(x)dx=1 \\tag{2} \\] 5.4.1 Additional notes (PMF and PDF) the pmf is then defined as the difference between consecutive CDF values pmf and pdf are probability measures, and these properties that satistfy the pmf or pdf and derived from the axioms of kolmogorov. 5.5 Expected Value \\[ E[X] = \\sum_{x \\in R_x} xp(x) \\tag{Discrete} \\] \\[ E[X] = \\int_{-\\infty}^\\infty{xf(x)}dx \\tag{Continous} \\] What if the discrete set is infinitely countable? The sum needs to converge absolutely for E(X) to exist. Population average is 1/n sum x_i 5.6 Properties of Expected Value What happens when the random variable Linearity of Expectation 5.7 Variance The variance of a random variable is the expected value of the squared deviation from the mean. It is implicit that expectation of X is defined, however even if E(X) exists it is possible that Var(X) is infinite \\[ \\\\ Var(X) = \\mathbb{E}([X − \\mathbb{E}[X]^2) = \\sum_{x \\in A}(x-\\mu)^2 \\tag{Discrete} p(x)\\] \\[ Var(x) = \\int_{-\\infty}^{\\infty}{\\mathbb{E}([X − \\mathbb{E}[X]^2)}dx = \\int_{-\\infty}^{\\infty}{\\sum_{x \\in A}(x-\\mu)^2}f(x)dx \\tag{Continous} \\] The shortcut formula for variance is \\(\\mathbb{E}[X^2]-\\mathbb{E}[X]^2\\) [proof draft on ipad] When Var(X) = 0, variance is constant. [proof draft on ipad] if a random variable X is equal to its expected value E[X] with probability 1, then the random variable is constant. Note that the converse is not necessarily true; a constant random variable may not always be equal to its expected value. Properties of variance tend to be derived from expectation 5.8 Moments Moments are used to describe the shape of a random variable distribution, moments are quantitative measures. \\(E[X]\\) - First Moment is the expected value \\(E[X^2]\\) - NOT ACTUALLY variance \\(E[X^3]\\) - NOT ACTUALLY skew \\(E[X^4]\\) - NOT ACTUALLY kurtosis The second central moment is variance the standardized third central moment of X is skew Kurtosis is a measure that is based on the fourth moment and the variance of X. Additional Notes the existence of higher moments implies the existence of lower moments Mixed moments are moments involving multiple variables. \\(E[X^n]\\) - \\(n\\)th moment of X 5.9 Standardized Random Variables Standardization is particularly useful if two or more random variables with different distributions must be compared \\(X^*\\) denotes the standardized random variable X Method of inverse transformation for continous only ??? 5.10 Law of the Unconscious Statistician (LOTUS) The relation between expected value of random variable X and how we can use it to calculate E[g(x)]. Transformations of \\[ E[g(X)] = \\sum_{x \\in R_x} g(x)p(x) \\] Proof: discrete AND continous Corollary: Importance: We have implied that E(X) is linear Also called the Change of Variables Theorem?? Misc how is a process different that a random variable: A random variable is a mathematical function that assigns a numerical value to each outcome of a random experiment or a probabilistic event. It is a way to represent the uncertainty associated with an event, and it can be used to calculate probabilities of different outcomes. For example, the outcome of a coin toss can be represented by a random variable that takes the value 1 if the coin lands heads and 0 if it lands tails. A process, on the other hand, is a sequence of random variables that evolve over time or space. It represents a system that changes over time according to some probabilistic rules. For example, the temperature of a room can be represented as a process that changes over time, where the temperature at each moment is a random variable that depends on the temperature at the previous moment, the heating and cooling systems in the room, and other factors. In summary, a random variable represents the uncertainty associated with a single event, while a process represents the evolution of a system over time or space, which involves a sequence of random variables. "],["special-distributions-of-discrete-random-variables.html", "Chapter 6 Special distributions of discrete random variables 6.1 Bernoulli Random Variables 6.2 Binomial Random Variables 6.3 Geometric Random Variables 6.4 Negative Binomial Random Variables 6.5 Hypergeometric Random Variables", " Chapter 6 Special distributions of discrete random variables 6.1 Bernoulli Random Variables \\[ X \\sim Bern(p) \\qquad R_x = \\{0,1\\} \\] A special case of the binomial distribution for a single trial, i.e., \\(n=1\\). Bernoulli trial is an experiment with two possible outcomes. A Bernoulli random variable itself uses these two possible outcomes, namely success and failure where the random variable takes the values of these outcomes and defines them to be \\(X(\\text{Success}) = 1\\) and \\(X(\\text{Failure}) = 0\\), respectively. 6.1.1 PMF \\[ \\begin{equation} p(x) = P(X = x)= \\begin{cases} p &amp; \\text{if } x = 1\\\\ 1 - p = q &amp; \\text{if } x = 0\\\\ 0 &amp; \\text{if } x \\not\\in R_x \\end{cases} \\end{equation} \\] 6.1.2 Parameter Details \\[ 0 \\le p \\le 1 \\] 6.1.3 Spread / Dispersion Equations \\[ E(X) = p \\qquad Var(X) = p(1-p) \\qquad \\sigma_x = \\sqrt{p(1-p)} \\] 6.1.4 Additional Notes A Bernoulli random variable is an indicator function. Alternative expressions for the Bernoulli pmf include:: \\[ P(X = k) = p^k (1-p)^{(1-k)} \\quad k \\in \\{0,1\\} \\] Bernoulli pmf takes on two discrete values, and it jumps abruptly from one value to the other at the point where the value of the random variable changes from 0 to 1, which can be shown graphically with its CDF. This is similar to other discrete random variables. can be generalized to more than 2 outcomes Bernoulli trial is an experiment with two possible outcomes, this is not the same as a Bernoulli random variable… or a Bernoulli process. 6.2 Binomial Random Variables \\[ X \\sim Binom(n,p) \\quad R_x = \\{0,1,2,...,n\\} \\] A binomial random variable is used for determining the number of successes in a fixed number of independent Bernoulli trials, all of which have the same fixed probability of success. For example, flipping a coin 10 times and counting the number of heads would be an example of a binomial random variable. Calculating where X = 3 (or any value of x in the support set) would be a result obtained from the random variable. 6.2.1 Parameter Details p = probability of success, n = number of trials parameters n and p represents the number of successes in n independent Bernoulli trials, where each trial has a fixed probability of success, denoted by p. 6.2.2 PMF \\[ \\begin{equation} p(x) = P(X= x) = \\begin{cases} \\binom{n}{x}p^x(1-p)^{n-x} &amp; \\text{if } x = 0,1,2,...,n\\\\ 0 &amp; \\text{if } x \\not\\in R_x \\end{cases} \\end{equation} \\] 6.2.3 Spread / Dispersion Equations \\[ E(X) = np \\quad Var(X) = np(1-p) \\quad \\sigma_x = \\sqrt{np(1-p)} \\] 6.2.4 Additional Notes The name is the binomial expression is given because of the use of the binomial expansion theorem used to show that p is a pmf finding the maximum (pg. 182) The binomial distribution is the basis for the popular binomial test of statistical significance A binomial random variable that has a single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment, and a sequence of outcomes is called a Bernoulli process; 6.3 Geometric Random Variables \\[ X \\sim Geo(p) \\qquad R_x = \\{1,2,3,...\\} \\] A geometric random variable is used to find the number of trials that are needed to get the first success in a Bernoulli process (a sequence of *iid* Bernoulli trials is called a Bernoulli process). In other words, a geometric random variable represents the number of failures that occur before the first success in a sequence of independent Bernoulli trials. The probability distribution of a geometric random variable is derived from the Bernoulli distribution. Note that Bernoulli random variable is a single experiment, binomial is n experiments, but geometric is infinitely many experiments. 6.3.1 PMF \\[ \\begin{equation} p(x) = P(X= x) = \\begin{cases} p(1-p)^{x-1} &amp; \\text{if } x = 1,2,...,n\\\\ 0 &amp; \\text{if } x \\not\\in R_x \\end{cases} \\end{equation} \\] 6.3.2 Parameter Details 0 &lt; p &lt; 1 p each obs the same probability of success, namely p 6.3.3 Spread / Dispersion Equations \\[ E(X) = \\frac{1}{p} \\qquad Var(X) = \\frac{1-p}{p^2} \\quad \\sigma_x = \\frac{\\sqrt{1-p}}{p} \\] 6.3.4 Additional Notes The case where there are infinite trials without success… Often used to model situations where you repeatedly perform a binary experiment. Memoryless property: “independent trials do not have a memory”, considering what happens upon conditioning a geometric random. Applies to the geometric distribution as \\(P( X &gt; a + b | x &gt; a ) = P ( x &gt; b )\\) \\(E(X)\\) is obviously the average number of trials, knowing the past does not affect the future.. While we have examined the number of trials that are needed to get the first success in a Bernoulli process, the distribution can also be used to denote the number of failures before the first success, in which case the support would obviously begin at 0 instead of 1, and the pmf would look a bit different also. 6.4 Negative Binomial Random Variables \\[ X \\sim Geom(r,p) \\qquad R_x = {r, r + 1, r + 2, r + 3, ...} \\] A negative binomial random variable is a generalization of a geometric random variable, where \\(X\\) represents the number of trials/experiments until the \\(rth\\) success occurs 6.4.1 Parameter Details r, p 6.4.2 PMF \\[ p(x; r,p) = P(X= x) = \\binom{x-1}{r-1}p^r(1-p)^{x-r}, \\qquad 0 &lt; p &lt; 1, \\qquad x = r, r + 1, r + 2, ... \\] 6.4.3 Spread / Dispersion Equations \\[ E(X) = \\frac{r}{p} \\qquad Var(X) = \\frac{r(1-p)}{p^2} \\quad \\sigma_x = \\frac{\\sqrt{r(1-p})}{p} \\] 6.4.4 Additional Notes many alternative formulations aka the pascal distribution 6.5 Hypergeometric Random Variables \\[ X \\sim HyperGeometric(D, N, n) \\qquad R_x = \\{0,1,2,...\\} \\] n are drawn at random and without replacement. 6.5.1 PMF \\[ P_X(k)= P(X = k) = \\frac{{K \\choose k} {N-K \\choose n-k}}{N \\choose n} \\] 6.5.2 Parameter Details \\(N\\) is the total population size \\(K\\) is the number of individuals in the population that have the attribute of interest \\(n\\) is the sample size \\(k\\) is not a parameter, it is the number of individuals in the sample that have the attribute of interest 6.5.3 Spread / Dispersion Equations \\[ E(k)=\\frac{nK}{N} \\qquad Var(k)=\\frac{nK}{N}\\frac{N-K}{N}\\frac{N-n}{N-1} \\] \\[ E(k) = \\sum_{i=1}^{n} k_i P(k_i) \\] \\[ Var(k) = \\sum_{i=1}^{n} (k_i - E(k))^2 P(k_i) \\] 6.5.4 Additional Notes "],["poisson-random-variables.html", "Chapter 7 Poisson Random Variables 7.1 Spread and Dispersion", " Chapter 7 Poisson Random Variables \\[ X \\sim Pois(\\lambda) \\quad R_x = \\{0,1,2,...\\} \\] A Poisson Random variable can be used to approximate a binomial random variable if \\(n\\) is large and \\(p\\) is small. (e.g. lottery tickets sold and winner tickets). This is because a Poisson probability mass function is the limit of a binomial probability mass function. Aside from approximating the binomial distribution, The Poisson distribution appears in connection with the study of sequences of random events occurring over time. [Theorem 5.2] 7.0.1 Parameter Details \\[ \\lambda \\in (0,\\infty) \\quad,\\quad \\lambda = np \\] 7.0.2 PMF \\[ \\begin{equation} p(X=x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}, \\quad x = 0,1,2,... \\end{equation} \\] 7.0.3 Support Set Details number of occurrences 7.1 Spread and Dispersion \\[ E(X) = np = \\lambda \\qquad Var(X) = (\\lambda + \\lambda^2) - \\lambda^2 = \\lambda \\qquad \\sigma_x = \\sqrt{\\lambda} \\] 7.1.1 Additional Notes [\\(R_x = \\mathbb{N_0} = \\{x \\in \\mathbb{N} | x &gt; 0 \\}\\)] possible alternate way to denote support Poisson processes came about in the 20th century, but Poisson first introduced the concept of the Poisson random variable in the early 19th century. \\(np \\le 10\\) and \\(p &lt; 0.1\\) Since the Possion rv itself has a pmf, therefore it can be used as a probability measure. [remark in textbook] “Poisson process is a stochastic process that models the arrival of events over time, while a Poisson random variable is a discrete random variable that represents the number of events occurring in a fixed time interval, given that the events occur independently and with a constant rate.” "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
