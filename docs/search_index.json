[["index.html", "Notes for Math, Probability, and Statistics Chapter 1 Introduction", " Notes for Math, Probability, and Statistics Jessica B 2023-05-31 Chapter 1 Introduction This is a book of notes for math, probability, and statistics. In probability, we solve forwards. It starts with an exact and well-defined rule. We use this rule to predict what will happen in the future. We don’t know the results, but probability allows us to quantify what should happen. In statistics, we solve backwards. It starts with the end results, known as data. We take this data and try to determine what well-defined rules created it. T Janesky Please do not try to use the mobile browser on current version. "],["axioms-of-kolmogorov.html", "Chapter 2 Axioms of Kolmogorov 2.1 Implied consequences of the Axioms 2.2 Sets, Sample Spaces, and events", " Chapter 2 Axioms of Kolmogorov Non-negativity Axiom \\[ \\text{For any event A in our sample space, } \\mathbb{P}(A)≥0 \\] Unity Axiom \\[ \\text{Normalization, also called the assumption of unit measure,}\\\\ \\text{defines the probability of the sample space } \\Omega \\text{ as } \\mathbb{P}(\\Omega)=1 \\] \\(\\sigma\\)-additivity Axiom \\[ \\text{Any countable sequence of disjoint (mutually exclusive) sets satisfies} \\\\ \\mathbb{P}(\\bigcup_{i=1}^{\\infty}E_{i}) = \\sum_{n=1}^{\\infty}\\mathbb{P}(E_{i}) \\qquad\\text{where }\\ E_i\\cap E_j = \\varnothing, \\quad \\forall i\\not=j \\] Additional Notes These axioms allow us to derive the theorems and properties that we frequently come across in the study of probability. Some authors tend to just use finite additivity as the third axiom. Stated in two axioms: \\((1) \\qquad \\text{Axiom 1 }\\mathbb{P(\\varnothing) =0, P(\\Omega)=1}, \\\\ (2) \\qquad\\sigma-\\text{additivity}\\) If finite additivity is proven using the third axiom, why is it used to prove the 3rd axiom? 2.1 Implied consequences of the Axioms Demonstrating these immediate consequences illustrates the power of the third axiom, and its interaction with the remaining two axioms. \\[ \\text{ Probability of the empty set} \\\\ \\mathbb{P}(\\varnothing) = 0 \\tag{Theorem 2.1} \\] \\[ \\text{Finite Additivity} \\\\ \\mathbb{P}(\\bigcup_{n=1}^{N} E_i)=\\sum_{n=1}^{N}\\mathbb{P}(E_i) \\tag{Theorem 2.2} \\] hint: for finite additive sets use mathematical induction \\[ \\text{Monotonicity} \\\\ A\\subseteq B \\text{ then }\\mathbb{P}(A)\\le\\mathbb{P}(B) \\tag{Theorem 2.3} \\] Understand that \\(A\\subseteq B\\) means that if a occurs, then B must occur \\[ \\text{The numeric bound} \\\\ 0\\le\\mathbb{P}(E)\\le1, \\qquad\\forall E\\in F \\tag{Theorem 2.3} \\] \\[ \\text{The complement rule} \\\\ \\mathbb{P}(E^c) = \\mathbb{P}(\\Omega-E) = 1 - \\mathbb{P}(E)\\tag{Theorem 2.4} \\] \\[ \\text{Inclusion-Exclusion Principal} \\\\ P(A\\cup B)=P(A) + P(B)-P(AB) \\tag{Theorem 2.5} \\\\ \\] \\[ \\\\ \\text{Generalized Inclusion-Exclusion Principal} \\\\ \\text{}\\mathbb{P}(ABC) \\tag{Theorem 2.6} \\] \\[ \\text{Equally Likely Theorem} \\\\ \\mathbb{P}(A)=\\frac{N(A)}{N}\\tag{Theorem 2.7} \\] Naive definition of probability \\[ \\text{No Name Theorem} \\\\ \\mathbb{P}(A) = P(AB) + P(AB^c) \\tag{Theorem 2.8} \\] \\[ \\text{Boole&#39;s Inequality} \\\\ \\mathbb{P}(\\bigcup_{i=1}^{\\infty}E_{i}) \\le \\sum_{n=1}^{\\infty}\\mathbb{P}(E_{i}) \\] [Future sections coming soon] ### A word of Probability Measures ### Continuity of Probability Functions 2.2 Sets, Sample Spaces, and events Sets are collections of distinct elements. A sample space is the set of disjoint, collectively exhaustive outcomes taken at a determined level of granularity. A sample space can be described as finite or infinite, discrete or continuous. A sample space can be described with the following notation \\[ A\\cup B=\\{x| x∈A \\cup x∈B\\} \\\\ A^c=\\{x|x\\not\\in A\\} \\] 2.2.1 Set Notation and LaTex code. Symbol Name LaTeX \\(\\cup\\) Intersection \\cup \\(\\cap\\) Union \\cap \\(\\in\\) Belongs to \\in \\(\\varnothing\\) Null set \\varnothing \\(\\Omega\\), \\(S\\) Universal set \\Omega \\(\\omega\\), \\(s\\) Atom, singleton \\omega \\(\\subset\\) Proper subset \\subset \\(\\subseteq\\) Subset, S is contained within A \\subseteq \\(\\bigcup\\) infinitary union, generalized union, unified union \\bigcup \\(\\bigcap\\) infinitary intersection, generalized intersection, unified intersection cap \\bigcap 2.2.2 Some Set Definitions Name Definition Rule Complement The complement of event A is… \\(P(A^c) = 1 - P(A)\\) Sum Rule The probability of the union of two mutually exclusive events A and B \\(P(A \\cup B) = P(A) + P(B)\\) Difference Rule The probability of the difference between two events A and B \\(P(A - B) = P(A) - P(A \\cap B)\\) Certainty The probability of the sample space (the set of all possible outcomes) is 1, which represents absolute certainty \\(P(\\Omega) = 1\\) Impossibility The probability of an impossible event is 0 \\(P(\\varnothing) = 0\\) Mutual Exclusivity Two events A and B cannot occur simultaneously, in terms of probability \\(P(A \\cap B) = 0\\) Note that Impossibility and Certainty are both themselves axioms 2.2.3 Relational Laws Name Law Communicative \\(AB = BA\\) Associative \\((AB)C = A(BC)\\) Distributive \\(AB \\cup C = (A \\cup C)(B \\cup C) ,\\quad A(B\\cup C) = AB \\cup AC\\) Demorgans First Law \\((A \\cup B)^c = A^cB^c\\) Demorgans Second Law \\((AB)^c = A^c \\cup B^c\\) "],["combinatorics.html", "Chapter 3 Combinatorics 3.1 Counting Principal 3.2 Permutations 3.3 Combinations 3.4 Number of Sets in a Subset", " Chapter 3 Combinatorics 3.1 Counting Principal The Fundamental Counting Principle, I also referred to as the generalized counting principal, the rule of product, the multiplication principal, and the multiplication rule. The rule states that the number different possible outcomes for a sequence of \\(n\\) stages is the product of the number of different ways each event can occur. \\[ \\text{Let }E_1, E_2, ..., E_k \\text{ be sets of events, where each set has }n_1,n_2, ...,n_k \\text{ respective elements.} \\\\ \\text{Then there are }n_1×n_2×n_3×···×n_k \\text{ combinations in which we, first,} \\\\ \\text{choose an element of }E_1, \\text{then choose element of }E_2, \\text{ ... , ending with } E_k. \\] - E_k-1 ,E_k Combinatorial principles - Wikipedia The counting principal can be visualized with a tree graph. There are some immediate rules that can be followed from the counting principal. Rule Equation Permutations, w/ Replacement \\(n^k\\) Permutations w/o Replacement \\(\\frac{n!}{(n-r)!}\\) Combinations, w/o Replacement \\(\\frac{n!}{r!(n-r)!}\\) Combinations w/ Replacement \\(\\binom{n+k-1}{k}\\) Number of Possible Subsets in a Set \\(2^n\\) 3.2 Permutations A permutation is the number of ways we can order \\(n\\) distinct objects. From the generalized counting principle we have \\(n\\) ways to make the first selection. Then we will have one fewer way to make our next selection, and so on… until we only have one option for the last selection. This results in the equation \\[ (n)(n−1)(n−2)···(1)=n! \\] We use the notation \\(_nP_r\\) to denote the number of permutations of a set \\(A\\) containing \\(n\\) elements taken \\(r\\) at a time where \\((1 ≤ r ≤ n)\\) The number of r-element permutations of a set containing n objects is given by \\[ _nP_r = \\frac{n!}{(n-r)!} \\] (note: to avoid division by zero when \\(n=r\\) we define \\(0! = 1\\)) To derive the formula for \\(_nP_r\\) we consider the number of choices for each selection. Since \\(A\\) has \\(n\\) elements, the number of choices for the first object in the \\(r\\)-element permutation is \\(n\\). For the next selection there will be \\(n-1\\) options, followed by \\(n-2\\) options for the selection that follows after that, we do this until our last selection, which is the \\(r\\)th event (or object) which has \\(n − (r − 1)\\) possible choices. ## _____ _____ _____ ... _____ ## (n) (n-1) (n-2) ... (n-(r-1)) We will always be accounting for the ways you can permeate \\(r\\) object, the result of \\(n - (r - 1)\\) is the number of objects taken into account. This leads us to the equation \\[ _nP_r =n(n−1)(n−2)···(n−r+1) \\] Aside: Permutations with \\(_nP_n\\) equate to \\[ _nP_n =n(n−1)(n−2)···(n−n+1)=n! \\] Manipulating the equation \\(n(n−1)(n−2)···(n−r+1)\\) leads us to the general formula \\[ _nP_r = \\frac{n!}{(n-r)!} \\] 3.2.1 Permutations with Replacement Using the counting principal we see that the number of permutations when we use replacement sampling is equal to \\[ n^k = (n)(n)....(n_k) \\] 3.2.2 Permutations with distinguished elements The formula above is valid only if all of the objects of the set are distinguishable from each other. If there are repeated elements then we must divide to cancel out the permutations that are a result of repeated elements \\[ \\frac{n!}{n_1! × n_2 ! × · · · × n_k!} \\] Consider the last name Brungard and the name Karapanian. One has repeating elements. If for some reason we wanted to know the possible ways to rearrange these letters: Brungard \\[ 8! = 40320 \\] Karapanian Here are ten letters, but only 6 distinct letters, 4 are the letter a and 2 are the letter n \\[ \\frac{10!}{4! *2!}= 75600 \\] While there are still more ways to permiate the longer last name, consider if you did not account for repeated characters… the overcount is over three million.. factorial(10)/(factorial(4)*factorial(2)) ## [1] 75600 factorial(10) ## [1] 3628800 3.3 Combinations we have for \\(r \\le n\\) \\[ \\binom{n}{r}=\\frac{n!}{r!(n-r)!} \\] We are calculating the number of \\(r\\)-element subsets from a \\(n\\)-element set, where order matters. This is the number of all r-element combinations of n objects, where we only use valid non-negative integers (e.g. 0,1,2, …) where \\(r \\le n\\). [add derivation, xr! = npr] 3.3.1 Combinations with replacement \\[ \\binom{n+k-1}{k} \\] 3.3.2 Useful Relations Choosing all and choosing nothing There is only one combination to choose all elements in a set. Similarly, there is only one way to choose nothing. \\[ \\binom{n}{n}=1 \\qquad \\&amp; \\qquad \\binom{n}{0}=1 \\] Both relations can be easily be shown algebraically \\[ \\binom{n}{n}=\\frac{n!}{n!(n-n)!}=1 \\] Choosing 1 from n objects is the same as choosing n-1 fron n objects \\[ \\binom{n}{1}=\\binom{n}{n-1} \\] consider this generalization where \\(0 \\le r \\le n\\) \\[ \\binom{n}{r}=\\binom{n}{n-r} \\] and \\[ \\binom{n+1}{r}=\\binom{n}{r}+\\binom{n}{r-1} \\] 3.4 Number of Sets in a Subset The set of all subsets of A is called the power set of A. We can calculate the number of subsets in a set as \\(2^n\\), because each element can be either included or excluded (hence the two options) [write more thoughts about this and how to verify algebraically or using combinatorics] ## Examples [coming soon] ## Practice Problems [coming soon] example 2.22 and binomial expansion "],["conditional-probability.html", "Chapter 4 Conditional Probability 4.1 Conditional Probability is a Probability Measure 4.2 Reduction of a Sample Space 4.3 Law of Multiplication 4.4 Law of Total Probability 4.5 Bayes’ Formula", " Chapter 4 Conditional Probability Conditional probability is not a theorem, nor a conjecture. It is not a lemma or a corollary. Instead conditional probability is a fundamental concept which is inherently understood…. It is obvious that the conditional probability \\(\\mathbb{P}(A|B)\\) gives an advantage when knowing the occurrence of B changes the occurrence of A. The probability of \\(\\mathbb{P}(A|B)\\) is obviously given by the ratio of the relative frequency of the intersection of A and B and the relative frequency of B. We can also state this as “the ratio of the probability of joint occurrence of A and B and the probability of B.” Conditional probability can be can be visualized when we think in terms of area…. We define conditional probability as \\[ \\mathbb{P}(A|B)=\\frac{\\mathbb{P}(AB)}{\\mathbb{P}(B)} \\] where \\(\\mathbb{P}(B)&gt;0\\). [Supporting example coming] Intersection versus joint occurrence of events: I found myself getting bogged down in set theory. Set Theory: P(AB) is the intersection of common elements between sets A and B. Joint occurrence better describes the probability that events are to occur. 4.1 Conditional Probability is a Probability Measure That is, they satisfy the same axioms that ordinary probabilities satisfy. This enables us to use the theorems that are true for probabilities for conditional probabilities as well. [Proofs coming soon] 4.2 Reduction of a Sample Space It is possible to reduce a sample space e.g. from (S to B) and have a smaller set of subsets. Making it easier to calculate conditioned probabilities. 4.3 Law of Multiplication Understand that conditional probability represents the relation between \\(\\mathbb{P}(A|B)\\) and \\(\\frac{\\mathbb{P}(AB)}{\\mathbb{P}(B)}\\) where \\(\\mathbb{P}(B) &gt; 0\\). By simply multiplying both sides by the \\(\\mathbb{P}(B)\\), The law of multiplication demonstrates that probability of the joint occurrence of A and B is the product of the probability of B and the conditional probability of A given that B has occurred. \\[ \\mathbb{P}(AB)=\\mathbb{P}(A|B)\\mathbb{P}(B), \\text{ where } \\mathbb{P}(B)&gt;0 \\] also, \\[ \\mathbb{P}(AB)=\\mathbb{P}(BA)=\\mathbb{P}(B|A)\\mathbb{P}(A), \\text{ where } \\mathbb{P}(A) &gt; 0 \\] We can also calculate the joint probability of three events by using association laws. Generalizing these theorems stated can be extended to \\(n\\) events to \\(k\\) events, the resulting formula can be proved by mathematical induction. $$ (A_1 A_2 A_3 …A_{n−1}) &gt; 0 \\ (A_1 A_2 A_3 …A_{n−1}A_n) = (A_1)P(A_2 | A_1)P(A_3 | A_1A_2)···(A_n | A_1A_2A_3 ···A_{n−1}) $$ 4.4 Law of Total Probability \\[ \\mathbb{P}(A) = \\mathbb{P}(A|B)\\mathbb{P}(A) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c) \\] Proof: Theorem 1.7 To generalize the theorem we define the partition of \\(S\\) 4.5 Bayes’ Formula Bayes’ Rule is a simple calculation but a big idea about beliefs. Consider that the partitioned sample space we imagine for the law of total probability. With Bayes’ Rule we are update our belief about something given that we know some other event is true or has occurred. We want to calculated the probability of an unknown event occuring. examining the hypothesis given evidence is true Certainly! Here’s the expression for Bayes’ theorem: \\[ P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)} \\] \\(P(H|E)\\) represents the probability of hypothesis \\(H\\) given evidence \\(E\\). \\(P(E|H)\\) denotes the probability of observing evidence \\(E\\) given the hypothesis \\(H\\). \\(P(H)\\) is the prior probability of hypothesis \\(H\\) \\(P(E)\\) represents the probability of observing evidence \\(E\\). In order to update our beliefs… we need to consider our prior knowledge \\(P(H)\\) [Future sections coming soon] ## Examples [coming soon] ## Practice Problems [coming soon] "],["random-variables.html", "Chapter 5 Random Variables 5.1 Transformations of Random Variables 5.2 Distribution Functions", " Chapter 5 Random Variables The concept of random variables allows us to explore what is unknown, or governed by randomness. We define a random variable as a real-valued function that maps a given event/outcome from a random experiment to a real number. The most formal, axiomatic definition of a random variable involves measure theory. \\[ X:\\Omega\\rightarrow \\mathbb{R} \\] Support Set The support set is the set of possible values of \\(X\\). Also refers to the domain of a random variable. Is discrete or continuous depending on the data involved. A random variable is not it’s probability distribution. A random variable is a representation of the possible outcomes of a random process, while the probability distribution provides a way to describe the likelihood or probability of each possible outcome. e.g. A binomial random variable is not a binomial distribution X is a function, not to be confused with a distribution function, or not f(x) is not p(x)! Random Variable Examples The outcome of a coin toss can be represented by a random variable that takes the value 1 if the coin lands heads and 0 if it lands tails. 5.1 Transformations of Random Variables A transformed variable will have a new distribution with different characteristics compared to the original distribution. Transformations on a single random variable Linear transformation: A linear transformation of a random variable X can be defined as Y = aX + b, where a and b are constants. Scales or shifts the variable. Exponential transformation: Y = e^X. Logarithmic transformation: A logarithmic transformation of a random variable X defined as Y = log(X). Box-Cox transformation: The Box-Cox transformation is a family of power transformations that can be used to stabilize the variance of a random variable. The transformation is defined as Y = [(X^λ)-1]/λ, where λ is an estimator. Square root transformation: Defined as Y = sqrt(X). This transformation can be useful in situations where the data is non-negative and the variance is proportional to the mean. Inverse transformation: An inverse transformation of a random variable X can be defined as Y = 1/X. This transformation can be useful in situations where the data is expressed in ratios or rates. Example transformations on multiple random variables Linear transformation: A linear transformation of X, Y, and Z can be defined as W = aX + bY + cZ, where a, b, and c are constants. This transformation can be useful in situations where we want to combine the information from three variables into a single variable. Multiplication: Multiplying three random variables X, Y, and Z can result in a new random variable W = XYZ. This can be useful in situations where we are interested in the product of three variables. Division: Dividing two random variables X and Y can result in a new random variable W = X/Y/Z. This can be useful in situations where we want to normalize one variable by two others. Addition: Adding three random variables X, Y, and Z can result in a new random variable W = X + Y + Z. This can be useful in situations where we are interested in the sum of three variables. Subtraction: Subtracting three random variables X, Y, and Z can result in a new random variable W = X - Y - Z. This can be useful in situations where we are interested in the difference between three variables. Function transformation: Applying a function to X, Y, and Z can result in a new random variable W = f(X,Y,Z). This can be useful in situations where we want to transform the variables in a non-linear way. In general, we can think of transforming n random variables using the above methods by defining a new random variable W as a function of the n variables, such as W = f(X1,X2,...,Xn). The choice of transformation will depend on the specific problem and the goals of the analysis. Additional Notes We can have several random variables defined on a sample space. Consider trying to randomly plot points on a plane in a circle, or within a boundary. this is a transformation on two random variables (X and Y are (x,y)) 5.2 Distribution Functions Definition: A distribution function of a random variable \\(X\\) is a function \\(F\\) from \\((-\\infty, +\\infty)\\) to \\(\\mathbb{R}\\) defined by\\(F(t)=P(X \\le t)\\). The CDF characterizes a random variable. Properties From the definition of a distribution function, the following properties are determined: F(t) is non-decreasing F(t) is right continuous satisfies \\(\\lim_{t \\rightarrow \\infty}= 1\\) satisfies \\(\\lim_{t \\rightarrow -\\infty}= 0\\) If the above properties are satisfied then we have a CDF. Recall that the CDF can characterize a random variable, how is this done? Considered the events that are represented as the following inequalities, if \\(P(X \\le t)\\) is known for all \\(t \\in \\mathbb{R}\\) all of the following events can be calculated. \\[ (X \\le a) \\qquad (X &lt; a) \\qquad (X \\ge a) \\qquad (X &gt; a) \\qquad (X = a) \\] \\[ (a \\le X \\le b) \\qquad (a &lt; X &lt; b) \\qquad (a &lt; X \\le b) \\qquad (a \\le X &lt; b) \\] \\[ F_X(t) = P(X \\le t) = \\sum_{\\{x \\in R_x | x\\le t\\}} p_X(x)\\tag{Discrete} \\] \\[ F(t) = P(X \\le t) = \\int_{-\\infty}^{t} f_X(x) dx \\tag{Continuous} \\] Additional Notes For discrete random variables, cdfs are step functions. P(X = a) = 0 PDF and PMF are derived from the CDF The probability integral transform theorem is also known as the Borel-Kolmogorov paradox or the Borel-Kolmogorov theorem: t can be shown that there exists a sample space S with a probability function and a random variable X over S such that the distribution function of X is F. "],["probability-distributions-discrete-and-continous.html", "Chapter 6 Probability Distributions (Discrete and Continous) 6.1 Probability Mass Functions 6.2 Probability Density Function 6.3 Measures of Center and Dispersion 6.4 Standardized Random Variables 6.5 Method of inverse transformation 6.6 Law of the Unconscious Statistician (LOTUS) 6.7 Method of Inverse Transformation", " Chapter 6 Probability Distributions (Discrete and Continous) 6.1 Probability Mass Functions Also called a PMF, probability function, or discrete probability function. Defined as a real-valued function from support set of a random variable \\(X\\) to \\(\\mathbb{R}\\), i.e. \\(p: \\mathbb{R_x} \\rightarrow \\mathbb{R}\\). \\[ p_X(x) = P(X=x) = P(\\{\\omega \\in \\Omega | X(\\omega)=x\\}) \\] a proper PMF satisfies the following properties \\[ p(x) \\ge 0 \\] and \\[ \\sum_{x \\in R_x}p(x)=1 \\] 6.2 Probability Density Function Defined as a real-valued function from \\(\\mathbb{R}\\) to \\(\\mathbb{R}\\), i.e. \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\) a proper PDF satisfies the following properties \\[ \\tag{1} f(x) \\ge 0, \\quad \\forall x \\in \\mathbb{R} \\] and \\[ \\int_{-\\infty}^{\\infty}f(x)dx=1 \\tag{2} \\] Additional notes (PMF and PDF) the pmf is then defined as the difference between consecutive CDF values the properties of the pmf and pdf show that they are probability measures, as shown by the axioms of kolmogorov. 6.3 Measures of Center and Dispersion 6.3.1 Expected Value \\[ E[X] = \\sum_{x \\in R_x} xp(x) \\tag{Discrete} \\] \\[ E[X] = \\int_{-\\infty}^\\infty{xf(x)}dx \\tag{Continous} \\] What if the discrete set is infinitely countable? The sum needs to converge absolutely for E(X) to exist. Population average is 1/n sum x_i Properties of Expected Value Linearity of Expectation 6.3.2 Variance The variance of a random variable is the expected value of the squared deviation from the mean. It is implicit that expectation of X is defined, however even if E(X) exists it is possible that Var(X) is infinite \\[ \\\\ Var(X) = \\mathbb{E}([X − \\mathbb{E}[X]^2) = \\sum_{x \\in A}(x-\\mu)^2 \\tag{Discrete} p(x) \\] \\[ Var(x) = \\int_{-\\infty}^{\\infty}{\\mathbb{E}([X − \\mathbb{E}[X]^2)}dx = \\int_{-\\infty}^{\\infty}{\\sum_{x \\in A}(x-\\mu)^2}f(x)dx \\tag{Continous} \\] Shortcut formula for variance \\[ \\mathbb{E}[X^2]-\\mathbb{E}[X]^2 \\] [proof] Additional Notes When Var(X) = 0, variance is constant. if a random variable X is equal to its expected value E[X] with probability 1, then the random variable is constant. Note that the converse is not necessarily true; a constant random variable may not always be equal to its expected value. Properties of variance tend to be derived from expectation 6.3.3 Moments Moments are used to describe the shape of a random variable distribution, moments are quantitative measures. \\(E[X]\\) - First Moment is the expected value \\(E[X^2]\\) - NOT ACTUALLY variance \\(E[X^3]\\) - NOT ACTUALLY skew \\(E[X^4]\\) - NOT ACTUALLY kurtosis The second central moment is variance the standardized third central moment of X is skew Kurtosis is a measure that is based on the fourth moment and the variance of X. Additional Notes the existence of higher moments implies the existence of lower moments Mixed moments are moments involving multiple variables. \\(E[X^n]\\) - \\(n\\)th moment of X 6.4 Standardized Random Variables Standardization is particularly useful if two or more random variables with different distributions must be compared \\(X^*\\) denotes the standardized random variable X 6.5 Method of inverse transformation 6.6 Law of the Unconscious Statistician (LOTUS) The relation between expected value of random variable X and how we can use it to calculate E[g(x)]. \\[ E[g(X)] = \\sum_{x \\in R_x} g(x)p(x) \\] Additional Notes Importance: We have implied that E(X) is linear Also called the Change of Variables Theorem?? 6.7 Method of Inverse Transformation "],["special-discrete-distributions.html", "Chapter 7 Special Discrete Distributions 7.1 Bernoulli Random Variables 7.2 Binomial Random Variables 7.3 Geometric Random Variables 7.4 Negative Binomial Random Variables 7.5 Hypergeometric Random Variables 7.6 Poisson Random Variables", " Chapter 7 Special Discrete Distributions 7.1 Bernoulli Random Variables \\[ X \\sim Bern(p) \\qquad R_x = \\{0,1\\} \\] A special case of the binomial distribution for a single trial, i.e., \\(n=1\\). Bernoulli trial is an experiment with two possible outcomes. A Bernoulli random variable itself uses these two possible outcomes, namely success and failure where the random variable takes the values of these outcomes and defines them to be \\(X(\\text{Success}) = 1\\) and \\(X(\\text{Failure}) = 0\\), respectively. PMF \\[ \\begin{equation} p(x) = P(X = x)= \\begin{cases} p &amp; \\text{if } x = 1\\\\ 1 - p = q &amp; \\text{if } x = 0\\\\ 0 &amp; \\text{if } x \\not\\in R_x \\end{cases} \\end{equation} \\] Parameter Details \\[ 0 \\le p \\le 1 \\] Spread / Dispersion Equations \\[ E(X) = p \\qquad Var(X) = p(1-p) \\qquad \\sigma_x = \\sqrt{p(1-p)} \\] Additional Notes A Bernoulli random variable is an indicator function. Alternative expressions for the Bernoulli pmf include:: \\[ P(X = k) = p^k (1-p)^{(1-k)} \\quad k \\in \\{0,1\\} \\] Bernoulli pmf takes on two discrete values, and it jumps abruptly from one value to the other at the point where the value of the random variable changes from 0 to 1, which can be shown graphically with its CDF. This is similar to other discrete random variables. can be generalized to more than 2 outcomes Bernoulli trial is an experiment with two possible outcomes, this is not the same as a Bernoulli random variable… or a Bernoulli process. 7.2 Binomial Random Variables \\[ X \\sim Binom(n,p) \\quad R_x = \\{0,1,2,...,n\\} \\] A binomial random variable is used for determining the number of successes in a fixed number of independent Bernoulli trials, all of which have the same fixed probability of success. For example, flipping a coin 10 times and counting the number of heads would be an example of a binomial random variable. Calculating where X = 3 (or any value of x in the support set) would be a result obtained from the random variable. Parameter Details p = probability of success, n = number of trials parameters n and p represents the number of successes in n independent Bernoulli trials, where each trial has a fixed probability of success, denoted by p. PMF \\[ \\begin{equation} p(x) = P(X= x) = \\begin{cases} \\binom{n}{x}p^x(1-p)^{n-x} &amp; \\text{if } x = 0,1,2,...,n\\\\ 0 &amp; \\text{if } x \\not\\in R_x \\end{cases} \\end{equation} \\] Spread / Dispersion Equations \\[ E(X) = np \\quad Var(X) = np(1-p) \\quad \\sigma_x = \\sqrt{np(1-p)} \\] Additional Notes The name is the binomial expression is given because of the use of the binomial expansion theorem used to show that p is a pmf finding the maximum (pg. 182) The binomial distribution is the basis for the popular binomial test of statistical significance A binomial random variable that has a single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment, and a sequence of outcomes is called a Bernoulli process; 7.3 Geometric Random Variables \\[ X \\sim Geo(p) \\qquad R_x = \\{1,2,3,...\\} \\] A geometric random variable is used to find the number of trials that are needed to get the first success in a Bernoulli process (a sequence of *iid* Bernoulli trials is called a Bernoulli process). In other words, a geometric random variable represents the number of failures that occur before the first success in a sequence of independent Bernoulli trials. The probability distribution of a geometric random variable is derived from the Bernoulli distribution. Note that Bernoulli random variable is a single experiment, binomial is n experiments, but geometric is infinitely many experiments. PMF \\[ \\begin{equation} p(x) = P(X= x) = \\begin{cases} p(1-p)^{x-1} &amp; \\text{if } x = 1,2,...,n\\\\ 0 &amp; \\text{if } x \\not\\in R_x \\end{cases} \\end{equation} \\] Parameter Details 0 &lt; p &lt; 1 p each obs the same probability of success, namely p Spread / Dispersion Equations \\[ E(X) = \\frac{1}{p} \\qquad Var(X) = \\frac{1-p}{p^2} \\quad \\sigma_x = \\frac{\\sqrt{1-p}}{p} \\] Additional Notes The case where there are infinite trials without success… Often used to model situations where you repeatedly perform a binary experiment. Memoryless property: “independent trials do not have a memory”, considering what happens upon conditioning a geometric random. Applies to the geometric distribution as \\(P( X &gt; a + b | x &gt; a ) = P ( x &gt; b )\\) \\(E(X)\\) is obviously the average number of trials, knowing the past does not affect the future.. While we have examined the number of trials that are needed to get the first success in a Bernoulli process, the distribution can also be used to denote the number of failures before the first success, in which case the support would obviously begin at 0 instead of 1, and the pmf would look a bit different also. 7.4 Negative Binomial Random Variables \\[ X \\sim Geom(r,p) \\qquad R_x = {r, r + 1, r + 2, r + 3, ...} \\] A negative binomial random variable is a generalization of a geometric random variable, where \\(X\\) represents the number of trials/experiments until the \\(rth\\) success occurs Parameter Details r, p PMF \\[ p(x; r,p) = P(X= x) = \\binom{x-1}{r-1}p^r(1-p)^{x-r}, \\qquad 0 &lt; p &lt; 1, \\qquad x = r, r + 1, r + 2, ... \\] Spread / Dispersion Equations \\[ E(X) = \\frac{r}{p} \\qquad Var(X) = \\frac{r(1-p)}{p^2} \\quad \\sigma_x = \\frac{\\sqrt{r(1-p})}{p} \\] Additional Notes many alternative formulations aka the pascal distribution 7.5 Hypergeometric Random Variables \\[ X \\sim HyperGeometric(D, N, n) \\qquad R_x = \\{0,1,2,...\\} \\] n are drawn at random and without replacement. PMF \\[ P_X(k)= P(X = k) = \\frac{{K \\choose k} {N-K \\choose n-k}}{N \\choose n} \\] Parameter Details \\(N\\) is the total population size \\(K\\) is the number of individuals in the population that have the attribute of interest \\(n\\) is the sample size \\(k\\) is not a parameter, it is the number of individuals in the sample that have the attribute of interest Spread / Dispersion Equations \\[ E(k)=\\frac{nK}{N} \\qquad Var(k)=\\frac{nK}{N}\\frac{N-K}{N}\\frac{N-n}{N-1} \\] \\[ E(k) = \\sum_{i=1}^{n} k_i P(k_i) \\] \\[ Var(k) = \\sum_{i=1}^{n} (k_i - E(k))^2 P(k_i) \\] Additional Notes 7.6 Poisson Random Variables \\[ X \\sim Pois(\\lambda) \\quad R_x = \\{0,1,2,...\\} \\] A Poisson Random variable can be used to approximate a binomial random variable if \\(n\\) is large and \\(p\\) is small. (e.g. lottery tickets sold and winner tickets). This is because a Poisson probability mass function is the limit of a binomial probability mass function. Aside from approximating the binomial distribution, The Poisson distribution appears in connection with the study of sequences of random events occurring over time. [Theorem 5.2] Parameter Details \\[ \\lambda \\in (0,\\infty) \\quad,\\quad \\lambda = np \\] PMF \\[ \\begin{equation} p(X=x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}, \\quad x = 0,1,2,... \\end{equation} \\] Support Set Details number of occurrences Spread and Dispersion \\[ E(X) = np = \\lambda \\qquad Var(X) = (\\lambda + \\lambda^2) - \\lambda^2 = \\lambda \\qquad \\sigma_x = \\sqrt{\\lambda} \\] Additional Notes [\\(R_x = \\mathbb{N_0} = \\{x \\in \\mathbb{N} | x &gt; 0 \\}\\)] possible alternate way to denote support Poisson processes came about in the 20th century, but Poisson first introduced the concept of the Poisson random variable in the early 19th century. \\(np \\le 10\\) and \\(p &lt; 0.1\\) Since the Possion rv itself has a pmf, therefore it can be used as a probability measure. [remark in textbook] “Poisson process is a stochastic process that models the arrival of events over time, while a Poisson random variable is a discrete random variable that represents the number of events occurring in a fixed time interval, given that the events occur independently and with a constant rate.” "],["special-continuous-distributions.html", "Chapter 8 Special Continuous Distributions 8.1 Continuous Uniform RV 8.2 Gaussian Random Variables 8.3 Exponential Random Variables", " Chapter 8 Special Continuous Distributions 8.1 Continuous Uniform RV \\(X\\) is uniformly distributed over the interval \\([a,b]\\), therefore two intervals of the same length will have the same numerical value. The uniform distribution on an interval is a special case of the general uniform distribution with respect to a measure, in this case Lebesgue measure (length measure) on R. \\[ X \\sim Unif(a,b) \\] \\[ \\begin{equation} f(x) = \\begin{cases} \\frac{1}{b-a} &amp; \\text{if } a \\le x \\le b\\\\ 0 &amp; \\text{otherwise} \\end{cases} \\end{equation} \\] Center and Dispersion \\[ E(X) = \\frac{a+b}{2} \\qquad Var(X) = \\frac{(b-a)^2}{12} \\qquad \\sigma_x = \\frac{b-a}{\\sqrt{12}} \\] Additional Notes There is also a discrete uniform random variable which is similarly defined. area of a retangle from b to a is??? improper integral of a constant from b to a ??? generalization piecewise constant pdf a and b are the min and max **values** respectively 8.2 Gaussian Random Variables \\[ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\] \\[ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp [-\\frac{(x-\\mu)^2}{2\\sigma^2}] \\] 8.3 Exponential Random Variables \\[ \\begin{equation} f_X(x) = F&#39;(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; \\text{if } x \\ge 0 \\\\ 0 &amp; x &lt; 0 \\end{cases} \\end{equation} \\] Center and Dispersion \\[ E(X) = \\sigma_x = \\frac{1}{\\lambda} \\qquad Var(X) = \\frac{1}{\\lambda^2} \\] Additional Notes memoryless property Relationship between Exponential and Geometric \\[ \\begin{equation} f_X(x) = F&#39;(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; \\text{if } x \\ge 0 \\\\ 0 &amp; x &lt; 0 \\end{cases} \\end{equation} \\] Center and Dispersion \\[ E(X) = \\sigma_x = \\frac{1}{\\lambda} \\qquad Var(X) = \\frac{1}{\\lambda^2} \\] Additional Notes "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
