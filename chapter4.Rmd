# Random Variables

The concept of random variables allows us to explore what is unknown, or governed by randomness. We define a random variable as a real-valued function that maps a given event/outcome from a random experiment to a real number. The most formal, [axiomatic](https://en.wikipedia.org/wiki/Axiomatic "Axiomatic") definition of a random variable involves [measure theory](https://en.wikipedia.org/wiki/Measure_theory "Measure theory").

$$
X:\Omega\rightarrow \mathbb{R}
$$

> Support Set
-   The support set is the set of possible values of $X$.
-   Also refers to the domain of a random variable.
-   Is discrete or continuous depending on the data involved.

> A random variable is not it's probability distribution.
- A random variable is a representation of the possible outcomes of a random process, while the probability distribution provides a way to describe the likelihood or probability of each possible outcome.
-   e.g. A binomial random variable is not a binomial distribution
-   X is a function, not to be confused with a distribution function, or not f(x) is not p(x)!

> Random Variable Examples
> The outcome of a coin toss can be represented by a random variable that takes the value 1 if the coin lands heads and 0 if it lands tails.

------------------------------------------------------------------------

## Transformations of Random Variables

A transformed variable will have a new distribution with different characteristics compared to the original distribution.

**Transformations on a single random variable

1.  Linear transformation: A linear transformation of a random variable X can be defined as Y = aX + b, where a and b are constants. This transformation can be useful in situations where we want to scale or shift the variable.

2.  Exponential transformation: An exponential transformation of a random variable X can be defined as Y = e\^X. This transformation can be useful in situations where the data is skewed or has a long tail.

3.  Logarithmic transformation: A logarithmic transformation of a random variable X can be defined as Y = log(X). This transformation can be useful in situations where the data is heavily skewed or the variable is expressed in units of magnitude.

4.  Box-Cox transformation: The Box-Cox transformation is a family of power transformations that can be used to stabilize the variance of a random variable. The transformation is defined as Y = [(X\^λ)-1]/λ, where λ is a parameter that can be estimated from the data.

5.  Square root transformation: A square root transformation of a random variable X can be defined as Y = sqrt(X). This transformation can be useful in situations where the data is non-negative and the variance is proportional to the mean.

6.  Inverse transformation: An inverse transformation of a random variable X can be defined as Y = 1/X. This transformation can be useful in situations where the data is expressed in ratios or rates.

**Transformations on multiple random variables (from the same sample space)

1.  Linear transformation: A linear transformation of X, Y, and Z can be defined as W = aX + bY + cZ, where a, b, and c are constants. This transformation can be useful in situations where we want to combine the information from three variables into a single variable.

2.  Multiplication: Multiplying three random variables X, Y, and Z can result in a new random variable W = XYZ. This can be useful in situations where we are interested in the product of three variables.

3.  Division: Dividing two random variables X and Y can result in a new random variable W = X/Y/Z. This can be useful in situations where we want to normalize one variable by two others.

4.  Addition: Adding three random variables X, Y, and Z can result in a new random variable W = X + Y + Z. This can be useful in situations where we are interested in the sum of three variables.

5.  Subtraction: Subtracting three random variables X, Y, and Z can result in a new random variable W = X - Y - Z. This can be useful in situations where we are interested in the difference between three variables.

6.  Function transformation: Applying a function to X, Y, and Z can result in a new random variable W = f(X,Y,Z). This can be useful in situations where we want to transform the variables in a non-linear way.

In general, we can think of transforming n random variables using the above methods by defining a new random variable W as a function of the n variables, such as W = f(X1,X2,\...,Xn). The choice of transformation will depend on the specific problem and the goals of the analysis.

**Additional Notes**

-   We can have several random variables defined on a sample space.

-   Consider trying to randomly plot points on a plane in a circle, or within a boundary. this is a transformation on two random variables (X and Y are (x,y))

------------------------------------------------------------------------

## Distribution Functions

Definition: A distribution function of a random variable $X$ is a function $F$ from $(-\infty, +\infty)$ to $\mathbb{R}$ defined by$F(t)=P(X \le t)$. The CDF characterizes a random variable.

Properties

From the definition of a distribution function, the following properties are determined:

1.  F(t) is non-decreasing
2.  F(t) is right continuous
3.  satisfies $\lim_{t \rightarrow \infty}= 1$
4.  satisfies $\lim_{t \rightarrow -\infty}= 0$

If the above properties are satisfied then we have a CDF.

------------------------------------------------------------------------

Recall that the CDF can characterize a random variable, how is this done? Considered the events that are represented as the following inequalities, if $P(X \le t)$ is known for all $t \in \mathbb{R}$ all of the following events can be calculated.

$$
(X \le a) \qquad (X < a) \qquad (X \ge a) \qquad (X > a) \qquad (X = a) 
$$

$$
(a \le X \le b) \qquad (a < X < b) \qquad (a < X \le b) \qquad (a \le X < b) 
$$

[needs proof from section 4.2]

------------------------------------------------------------------------

> In general, the respective discrete and continuous CDFs are as follows, but take a closer look at the formulas, they are using p(x) and f(x), respectively to calculate F(t). If the PDF and PMF are derived from the CDF, how are we using them to calculate the CDF?
>
> $$
> F_X(t) = P(X \le t) = \sum_{\{x \in R_x | x\le t\}} p_X(x)\tag{Discrete}
> $$
>
> $$
> F(t) = P(X \le t) = \int_{-\infty}^{t} f_X(x) dx \tag{Continuous} 
> $$
>
> $$
> F(t)
> $$

**Additional Notes**

-   For discrete random variables, cdfs are step functions.

-   P(X = a) = 0

-   PDF and PMF are derived from the CDF

-   The probability integral transform theorem is also known as the Borel-Kolmogorov paradox or the Borel-Kolmogorov theorem: t can be shown that there exists a sample space S with a probability function and a random variable X over S such that the distribution function of X is F.

------------------------------------------------------------------------
